{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ridge Regression**\n",
    "\n",
    "Ridge Regression is a regularized version of Linear Regression: a regularization term equal to $\\alpha \\sum_{i=1}^n \\theta_i^2$ is added to the cost function. This forces the learning algorithm to not only fit the data but also keep the model weights as small as possible. Note that the regularization term should only be added to the cost function during training. Once the model is trained, you want to evaluate the model's performance using the unregularized performance measure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Regularization` is a technique used in machine learning and statistics to prevent overfitting of models on training data. Overfitting occurs when a model learns the training data too well, including its noise and outliers, leading to poor generalization to new, unseen data. Regularization helps to solve this problem by adding a penalty to the model's complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Ridge regression, also known as `Tikhonov regularization`, is a type of linear regression that includes a regularization term. The key idea behind ridge regression is to find a new line that doesn't fit the training data as well as ordinary least squares regression, in order to achieve better generalization to new data. \n",
    "\n",
    "`This is particularly useful when dealing with multicollinearity (independent variables are highly correlated) or when the number of predictors (features) exceeds the number of observations (rows).\n",
    "`\n",
    "### **Key Concept:**\n",
    "- **Regularization**: Ridge regression adds a penalty equal to the square of the magnitude of coefficients. This penalty term (squared L2 norm) shrinks the coefficients towards zero, but it doesn't make them exactly zero.\n",
    "\n",
    "### **Mathematical Representation**:\n",
    "The ridge regression modifies the least squares objective function by adding a penalty term:\n",
    "\n",
    "$$ \\text{Minimize } \\sum_{i=1}^{n} (y_i - \\sum_{j=1}^{p} x_{ij} \\beta_j)^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2 $$\n",
    "\n",
    "where:\n",
    "- $ y_i $ is the response value for the ith observation.\n",
    "- $ x_{ij} $ is the value of the jth predictor for the ith observation.\n",
    "- $ \\beta_j $ is the regression coefficient for the jth predictor.\n",
    "- $ \\lambda $ is the tuning parameter that controls the strength of the penalty; $ \\lambda \\geq 0 $.\n",
    "\n",
    "\n",
    "In this code, `alpha` is the regularization strength $ lambda$. Adjusting `alpha` changes the strength of the regularization penalty. A larger `alpha` enforces stronger regularization (leading to smaller coefficients), and a smaller `alpha` tends towards a model similar to linear regression.\n",
    "\n",
    "### **Key Points**:\n",
    "- **Choosing Alpha**: Selecting the right value of `alpha` is crucial. It can be done using cross-validation techniques like `RidgeCV`.\n",
    "- **Standardization**: It's often recommended to standardize the predictors `(features)` before applying ridge regression.\n",
    "- **Bias-Variance Tradeoff**: Ridge regression balances the bias-variance tradeoff in model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.8 1.4]\n",
      "Intercept: 4.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# Target values\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# Ridge Regression Model\n",
    "ridge_reg = Ridge(alpha=1.0)  # alpha is the equivalent of lambda in the formula\n",
    "ridge_reg.fit(X, y)\n",
    "\n",
    "# Coefficients\n",
    "print(\"Coefficients:\", ridge_reg.coef_)\n",
    "# Intercept\n",
    "print(\"Intercept:\", ridge_reg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparision between the Ridge and the Linear Regression**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Coefficients: [1. 2.]\n",
      "Linear Regression Intercept: 3.0000000000000018\n"
     ]
    }
   ],
   "source": [
    "# comparing the ridge regression with the normal linear regression:\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "print(\"Linear Regression Coefficients:\", lin_reg.coef_)\n",
    "print(\"Linear Regression Intercept:\", lin_reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **`Note`**:\n",
    "\n",
    "1. Ridge regression is a technique used when the data suffers from multicollinearity (independent variables are highly correlated).\n",
    "\n",
    "2. In multicollinearity, even though the least squares estimates (OLS) are unbiased, their variances are large which deviates the observed value far from the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors.\n",
    "\n",
    "3. The hyperparameter α controls the amount of regularization. If α = 0 then Ridge regression is just Linear regression. If α is very large, then all weights end up very close to zero and the result is a flat line going through the data’s mean.\n",
    "\n",
    "### The Ridge regression cost function is:\n",
    " $J(θ) = MSE(θ) + α Σ θ²$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Coefficients: [0.8 1.4]\n",
      "Linear Regression Intercept: 4.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_reg = Ridge(alpha=1.0)\n",
    "\n",
    "# fit the model\n",
    "ridge_reg.fit(X,y)\n",
    "ridge_reg.fit(X, y)\n",
    "print(\"Linear Regression Coefficients:\", ridge_reg.coef_)\n",
    "print(\"Linear Regression Intercept:\", ridge_reg.intercept_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's try it on titanic dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>who</th>\n",
       "      <th>adult_male</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alive</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>woman</td>\n",
       "      <td>False</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>man</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third   \n",
       "\n",
       "     who  adult_male deck  embark_town alive  alone  \n",
       "0    man        True  NaN  Southampton    no  False  \n",
       "1  woman       False    C    Cherbourg   yes  False  \n",
       "2  woman       False  NaN  Southampton   yes   True  \n",
       "3  woman       False    C  Southampton   yes  False  \n",
       "4    man        True  NaN  Southampton    no   True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the dataset:\n",
    "\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['sex', 'age', 'fare', 'pclass', 'survived']\n",
    "df = df[columns]\n",
    "\n",
    "# handle the missing values:\n",
    "df['age'] = df['age'].fillna(df['age'].median())\n",
    "\n",
    "# Split the data into X and y:\n",
    "X = df.drop('survived', axis=1)\n",
    "y = df['survived']\n",
    "\n",
    "# train test split:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pipeline for OneHotEncoding and model\n",
    "cat_features = ['sex']\n",
    "num_features = ['pclass', 'age', 'fare']\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', 'passthrough', num_features),\n",
    "        ('cat', OneHotEncoder(), cat_features)])\n",
    "\n",
    "# Linear Regression Pipeline\n",
    "lr_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('regressor', LinearRegression())])\n",
    "\n",
    "# Ridge Regression Pipeline\n",
    "ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                 ('regressor', Ridge(alpha=1.0))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trian and evalute the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 0.1371682053082538\n",
      "Ridge Regression MSE: 0.13718838549258477\n",
      "Linear Regression R2: 0.4343621021516396\n",
      "Ridge Regression R2: 0.4342788855124956\n",
      "Linear Regression MAE: 0.287745694224429\n",
      "Ridge Regression MAE: 0.2882077593913576\n",
      "Linear Regression MAPE: 645238867583785.4\n",
      "Ridge Regression MAPE: 645983981155846.8\n",
      "Linear Regression RMSE: 0.3703622622625769\n",
      "Ridge Regression RMSE: 0.3703895051058882\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate Linear Regression\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict the model:\n",
    "lr_pred = lr_pipeline.predict(X_test)\n",
    "\n",
    "# evaluate the metrics:\n",
    "lr_mse = mean_squared_error(y_test, lr_pred)\n",
    "lr_r2 = r2_score(y_test, lr_pred)\n",
    "lr_mae = mean_absolute_error(y_test, lr_pred)\n",
    "lr_mape = mean_absolute_percentage_error(y_test, lr_pred)\n",
    "lr_rmse = np.sqrt(lr_mse)\n",
    "\n",
    "# Train and evaluate Ridge Regression\n",
    "ridge_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# predict the model:\n",
    "ridge_pred = ridge_pipeline.predict(X_test)\n",
    "\n",
    "# evaluate the model:\n",
    "ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "ridge_mape = mean_absolute_percentage_error(y_test, ridge_pred)\n",
    "ridge_rmse = np.sqrt(ridge_mse)\n",
    "\n",
    "# print the metrics:\n",
    "\n",
    "print(\"Linear Regression MSE:\", lr_mse)\n",
    "print(\"Ridge Regression MSE:\", ridge_mse)\n",
    "\n",
    "print(\"Linear Regression R2:\", lr_r2)\n",
    "print(\"Ridge Regression R2:\", ridge_r2)\n",
    "\n",
    "print(\"Linear Regression MAE:\", lr_mae)\n",
    "print(\"Ridge Regression MAE:\", ridge_mae)\n",
    "\n",
    "print(\"Linear Regression MAPE:\", lr_mape)\n",
    "print(\"Ridge Regression MAPE:\", ridge_mape)\n",
    "\n",
    "print(\"Linear Regression RMSE:\", lr_rmse)\n",
    "print(\"Ridge Regression RMSE:\", ridge_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression with alpha=0.1 MSE: 0.13717016510037283\n",
      "Ridge Regression with alpha=0.1 R2: 0.43435402059446004\n",
      "Ridge Regression with alpha=0.1 MAE: 0.28779202724886926\n",
      "Ridge Regression with alpha=0.1 MAPE: 645313585211062.1\n",
      "Ridge Regression with alpha=0.1 RMSE: 0.37036490803040834\n",
      "\n",
      "\n",
      "Ridge Regression with alpha=0.5 MSE: 0.13717813407700813\n",
      "Ridge Regression with alpha=0.5 R2: 0.4343211590783246\n",
      "Ridge Regression with alpha=0.5 MAE: 0.2879770777909805\n",
      "Ridge Regression with alpha=0.5 MAPE: 645611996636465.5\n",
      "Ridge Regression with alpha=0.5 RMSE: 0.37037566615128503\n",
      "\n",
      "\n",
      "Ridge Regression with alpha=1.0 MSE: 0.13718838549258477\n",
      "Ridge Regression with alpha=1.0 R2: 0.4342788855124956\n",
      "Ridge Regression with alpha=1.0 MAE: 0.2882077593913576\n",
      "Ridge Regression with alpha=1.0 MAPE: 645983981155846.8\n",
      "Ridge Regression with alpha=1.0 RMSE: 0.3703895051058882\n",
      "\n",
      "\n",
      "Ridge Regression with alpha=2.0 MSE: 0.13720984388428473\n",
      "Ridge Regression with alpha=2.0 R2: 0.4341903979541355\n",
      "Ridge Regression with alpha=2.0 MAE: 0.28866702943950884\n",
      "Ridge Regression with alpha=2.0 MAPE: 646724537644174.0\n",
      "Ridge Regression with alpha=2.0 RMSE: 0.3704184713054746\n",
      "\n",
      "\n",
      "Ridge Regression with alpha=5.0 MSE: 0.13728164583872146\n",
      "Ridge Regression with alpha=5.0 R2: 0.433894309611522\n",
      "Ridge Regression with alpha=5.0 MAE: 0.2900283203476822\n",
      "Ridge Regression with alpha=5.0 MAPE: 648919279828112.5\n",
      "Ridge Regression with alpha=5.0 RMSE: 0.37051537868045564\n",
      "\n",
      "\n",
      "Ridge Regression with alpha=10.0 MSE: 0.13742468274726724\n",
      "Ridge Regression with alpha=10.0 R2: 0.4333044710546732\n",
      "Ridge Regression with alpha=10.0 MAE: 0.2922435386615066\n",
      "Ridge Regression with alpha=10.0 MAPE: 652489842484830.0\n",
      "Ridge Regression with alpha=10.0 RMSE: 0.3707083526807391\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression with different alpha values:\n",
    "\n",
    "alphas = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0]\n",
    "\n",
    "for alpha in alphas:\n",
    "    ridge_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                     ('regressor', Ridge(alpha=alpha))])\n",
    "    ridge_pipeline.fit(X_train, y_train)\n",
    "    ridge_pred = ridge_pipeline.predict(X_test)\n",
    "    ridge_mse = mean_squared_error(y_test, ridge_pred)\n",
    "    ridge_r2 = r2_score(y_test, ridge_pred)\n",
    "    ridge_mae = mean_absolute_error(y_test, ridge_pred)\n",
    "    ridge_mape = mean_absolute_percentage_error(y_test, ridge_pred)\n",
    "    ridge_rmse = np.sqrt(ridge_mse)\n",
    "    print(f\"Ridge Regression with alpha={alpha} MSE:\", ridge_mse)\n",
    "    print(f\"Ridge Regression with alpha={alpha} R2:\", ridge_r2)\n",
    "    print(f\"Ridge Regression with alpha={alpha} MAE:\", ridge_mae)\n",
    "    print(f\"Ridge Regression with alpha={alpha} MAPE:\", ridge_mape)\n",
    "    print(f\"Ridge Regression with alpha={alpha} RMSE:\", ridge_rmse)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **About Me**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://scontent.flhe6-1.fna.fbcdn.net/v/t39.30808-6/449152277_18043153459857839_8752993961510467418_n.jpg?_nc_cat=108&ccb=1-7&_nc_sid=127cfc&_nc_ohc=6slHzGIxf0EQ7kNvgEeodY9&_nc_ht=scontent.flhe6-1.fna&oh=00_AYCiVUtssn2d_rREDU_FoRbXvszHQImqOjfNEiVq94lfBA&oe=66861B78\" width=\"150px\" style=\"border-radius: 50%;\"/>\n",
    "</div>\n",
    "\n",
    "## Muhammad Faizan\n",
    "\n",
    "🎓 **3rd Year BS Computer Science** student at the **University of Agriculture, Faisalabad**  \n",
    "💻 Enthusiast in **Machine Learning, Data Engineering, and Data Analytics**\n",
    "\n",
    "\n",
    "### 🌐 Connect with Me\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/faizanyousafonly/) | [LinkedIn](https://www.linkedin.com/in/mrfaizanyousaf/) | [GitHub](https://github.com/faizan-yousaf/)  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 💬 Contact Me\n",
    "- **Email:** faizanyousaf815@gmail.com\n",
    "- **WhatsApp:** [+92 306 537 5389](https://wa.me/923065375389)\n",
    "\n",
    "\n",
    "🔗 **Let’s Collaborate:**  \n",
    "I'm always open to queries, collaborations, and discussions. Let's build something amazing together!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
