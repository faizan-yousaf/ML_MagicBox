{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hyperparameter Tuning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Hyper parameter tuninig is the process of `finding the best hyperparameters` for a model. \n",
    "\n",
    "* Hyperparameters are the `parameters that are not learned by the model`.\n",
    "\n",
    "* They are set before the training process begins.\n",
    "\n",
    "* In this notebook, I will show you how to tune the hyperparameters of a model using the GridSearchCV and RandomizedSearchCV method. I will use the Random Forest Classifier model for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Types of Hyperparameters**:\n",
    "1. **Model Hyperparameters**: These are the hyperparameters that are `specific to the model` that we are using. For example, the number of trees in a Random Forest model.\n",
    "2. **Algorithm Hyperparameters**: These are the hyperparameters that are `specific to the algorithm` that we are using. For example, the learning rate in the Gradient Boosting algorithm.\n",
    "3. **Optimization Hyperparameters**: These are the hyperparameters that are `specific to the optimization algorithm` that we are using. For example, the batch size in the Stochastic Gradient Descent algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Types:\n",
    "\n",
    "1. **Grid Search**: Grid search is the process of `searching for the best hyperparameters` by manually specifying the hyperparameters and their values.\n",
    "   \n",
    "2. **Random Search**: Random search is the process of searching for the best hyperparameters by `randomly sampling the hyperparameters` and their values.\n",
    "\n",
    "3. **Bayesian Optimization**: Bayesian optimization is the process of searching for the best hyperparameters by `building a probabilistic model` of the objective function and using it to select the next hyperparameters to evaluate.\n",
    "\n",
    "4. **GradientBased Optimization**: Gradient-based optimization is the process of searching for the best hyperparameters by `computing the gradient of the objective function` with respect to the hyperparameters and using it to update the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the libraries:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset from sklearn.datasets ('iris'):\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "target\n",
      "frame\n",
      "target_names\n",
      "DESCR\n",
      "feature_names\n",
      "filename\n",
      "data_module\n"
     ]
    }
   ],
   "source": [
    "# use a for loop to show all the keys in the dataset:\n",
    "for i in iris.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature names of iris dataset are: \n",
      "  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "The target names of iris dataset are: \n",
      "  ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(f\"The feature names of iris dataset are: \\n \", iris.feature_names)\n",
    "\n",
    "print(f\"The target names of iris dataset are: \\n \", iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the data and the target:\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 396 candidates, totalling 1980 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "660 fits failed out of a total of 1980.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "406 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "254 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96       0.96       0.96       0.96666667 0.96\n",
      " 0.96666667 0.96       0.95333333 0.96666667 0.96666667 0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96666667 0.96666667 0.96       0.96       0.96666667\n",
      " 0.96       0.96       0.96666667 0.96666667 0.96       0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94       0.96       0.96       0.96       0.96666667 0.96666667\n",
      " 0.93333333 0.96       0.96       0.96666667 0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96       0.96666667 0.96       0.96666667 0.96666667\n",
      " 0.95333333 0.95333333 0.96       0.96       0.96       0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96666667 0.96666667 0.96666667 0.96       0.96       0.96666667\n",
      " 0.94666667 0.96       0.96666667 0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96666667 0.96666667 0.96       0.96666667 0.96666667\n",
      " 0.96       0.96666667 0.96       0.96666667 0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.96       0.96       0.96666667 0.96666667 0.96666667\n",
      " 0.95333333 0.96       0.96666667 0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96       0.96       0.96666667 0.96666667 0.96\n",
      " 0.95333333 0.96666667 0.96       0.96       0.96666667 0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96       0.96666667 0.96       0.96       0.96666667\n",
      " 0.95333333 0.96       0.96       0.96666667 0.96       0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.95333333 0.96       0.95333333 0.96       0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96       0.96       0.96666667 0.96       0.96666667\n",
      " 0.95333333 0.96666667 0.96       0.96666667 0.96666667 0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.95333333 0.96666667 0.96       0.96666667 0.96666667\n",
      " 0.96       0.96       0.96       0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96666667 0.96666667 0.96666667 0.96       0.96       0.96666667\n",
      " 0.96666667 0.96       0.96666667 0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.96       0.96666667 0.96       0.96666667 0.96\n",
      " 0.96       0.96       0.96666667 0.96666667 0.96       0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.95333333 0.96666667 0.96666667 0.96666667 0.96666667\n",
      " 0.94666667 0.96666667 0.96666667 0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96666667 0.96       0.96666667 0.96       0.96666667 0.96666667\n",
      " 0.95333333 0.96666667 0.96666667 0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96666667 0.96       0.96       0.96666667 0.96666667\n",
      " 0.96666667 0.96       0.96666667 0.96       0.96       0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.96       0.96666667 0.96       0.96       0.96666667\n",
      " 0.96       0.96       0.96666667 0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96666667 0.96666667 0.96       0.96       0.96\n",
      " 0.94666667 0.96       0.96       0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96666667 0.96666667 0.96666667 0.96666667 0.96\n",
      " 0.94666667 0.96       0.96       0.96666667 0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.96666667 0.96666667 0.96666667 0.96       0.96666667\n",
      " 0.94666667 0.95333333 0.96       0.96       0.96666667 0.96666667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.96       0.96666667 0.96666667 0.96666667 0.96666667 0.96666667\n",
      " 0.95333333 0.96666667 0.96       0.96       0.95333333 0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# call the model:\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# create a dictionary of parameters:\n",
    "\n",
    "param_grid = {'n_estimators': [10, 100, 200, 300, 400, 500],\n",
    "                'criterion': ['gini', 'entropy'],\n",
    "                'max_depth': [None, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "                'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# set up the GridSearchCV:\n",
    "\n",
    "grid = GridSearchCV(estimator=model , \n",
    "                    param_grid= param_grid, \n",
    "                    cv=5,\n",
    "                    scoring='accuracy',\n",
    "                    verbose=1,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "# fit the model:\n",
    "\n",
    "grid.fit(X, y)\n",
    "\n",
    "# print the best prarameters:\n",
    "\n",
    "print(f\"The best parameters are: {grid.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "20 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "16 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\Muhammad Faizan\\.conda\\envs\\python_machinelearning\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1052: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.95333333 0.96       0.96       0.95333333\n",
      "        nan        nan 0.96       0.96666667]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are: {'n_estimators': 500, 'max_features': 'log2', 'max_depth': 20, 'criterion': 'entropy'}\n"
     ]
    }
   ],
   "source": [
    "# now lets try the Random Search CV:\n",
    "\n",
    "random = RandomizedSearchCV(estimator=model,\n",
    "                            param_distributions = param_grid,\n",
    "                            cv=5,\n",
    "                            n_iter=10,\n",
    "                            scoring='accuracy',\n",
    "                            verbose=1,\n",
    "                            n_jobs=-1)\n",
    "\n",
    "# fit the model:\n",
    "\n",
    "random.fit(X, y)\n",
    "\n",
    "# print the best parameters:\n",
    "print(f\"The best parameters are: {random.best_params_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* In this notebook I practiced the concepts of HyperParameter Tuning using GridSearchCV and RandomizedSearchCV.\n",
    "* These are very useful tools to find the best parameters for the model.\n",
    "* I used the RandomForestClassifier as an example, but these tools can be used with any model.\n",
    "* I used the Iris dataset from sklearn.datasets.\n",
    "* I hope this notebook is useful for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# About Me:\n",
    "\n",
    "<img src=\"https://scontent.flhe6-1.fna.fbcdn.net/v/t39.30808-6/449152277_18043153459857839_8752993961510467418_n.jpg?_nc_cat=108&ccb=1-7&_nc_sid=127cfc&_nc_ohc=6slHzGIxf0EQ7kNvgEeodY9&_nc_ht=scontent.flhe6-1.fna&oh=00_AYCiVUtssn2d_rREDU_FoRbXvszHQImqOjfNEiVq94lfBA&oe=66861B78\" width=\"30%\">\n",
    "\n",
    "**Muhammd Faizan**\n",
    "\n",
    "3rd Year BS Computer Science student at University of Agriculture, Faisalabad.\\\n",
    "Contact me for queries/collabs/correction\n",
    "\n",
    "[Kaggle](https://www.kaggle.com/faizanyousafonly/)\\\n",
    "[Linkedin](https://www.linkedin.com/in/mrfaizanyousaf/)\\\n",
    "[GitHub](https://github.com/faizan-yousaf/)\\\n",
    "[Email] faizan6t45@gmail.com or faizanyousaf815@gmail.com \\\n",
    "[Phone/WhatsApp]() +923065375389"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_machinelearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
